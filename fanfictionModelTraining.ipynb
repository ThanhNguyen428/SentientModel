{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fanfictionModelTraining.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTeAR8FWnoar",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ed6e6eef-d17c-465e-c8cb-dcdbaeac9fbc"
      },
      "source": [
        "!pip install pyyaml h5py  # Required to save models in HDF5 format"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.18.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXPQH_xP2Up0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e791d99d-8d58-4214-ff22-037859f3e8be"
      },
      "source": [
        "#imports\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import string\n",
        "\n",
        "from string import punctuation\n",
        "from os import listdir\n",
        "from collections import Counter\n",
        "\n",
        "from keras.models import Sequential, save_model\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0NDAxvW5OZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open('xTrainLines.csv', newline='') as f:\n",
        "#     reader = csv.reader(f)\n",
        "#     xTrainLines = list(reader)\n",
        "\n",
        "with open('xTrainLines.txt') as temp_file:\n",
        "  xTrainLines = [line.rstrip('\\n') for line in temp_file]\n",
        "\n",
        "with open('xTestLines.txt') as temp_file:\n",
        "  xTestLines = [line.rstrip('\\n') for line in temp_file]\n",
        "\n",
        "with open('yTrain.txt') as temp_file:\n",
        "  yTrain = [int(line.rstrip('\\n')) for line in temp_file]\n",
        "\n",
        "with open('yTest.txt') as temp_file:\n",
        "  yTest = [int(line.rstrip('\\n')) for line in temp_file]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGfgv15fGhq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('vocab.txt') as temp_file:\n",
        "  vocab = [line.rstrip('\\n') for line in temp_file]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ryo7qqXCG1xK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evC_BW9emwQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the tokenizer\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "\n",
        "# fit the tokenizer on the documents\n",
        "tokenizer.fit_on_texts(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y5EL8YJhBtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQxQkoIRP9TN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnDYkE3O90F3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "\n",
        "class Metrics(Callback):\n",
        "  def on_train_begin(self, logs={}):\n",
        "    self.val_f1s = []\n",
        "    self.val_recalls = []\n",
        "    self.val_precisions = []\n",
        " \n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n",
        "    val_targ = self.validation_data[1]\n",
        "    _val_f1 = f1_score(val_targ, val_predict)\n",
        "    _val_recall = recall_score(val_targ, val_predict)\n",
        "    _val_precision = precision_score(val_targ, val_predict)\n",
        "    self.val_f1s.append(_val_f1)\n",
        "    self.val_recalls.append(_val_recall)\n",
        "    self.val_precisions.append(_val_precision)\n",
        "    print(\"— val_f1: %f — val_precision: %f — val_recall %f\" %(_val_f1, _val_precision, _val_recall))\n",
        "  \n",
        "metrics = Metrics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAgeZo789jJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode training data set\n",
        "xTrain = tokenizer.texts_to_matrix(xTrainLines, mode='freq')\n",
        "print(xTrain.shape)\n",
        "print(xTrain[0][:20])\n",
        "\n",
        "xTest = tokenizer.texts_to_matrix(xTestLines, mode='freq')\n",
        "print(xTest.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzqXQn3qp296",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0b5bc53e-32f8-4914-f8df-f9e0a4166ce3"
      },
      "source": [
        "#storing the shape for the future model\n",
        "\n",
        "n_words = xTest.shape[1]\n",
        "\n",
        "# define network\n",
        "model = Sequential()\n",
        "model.add(Dense(100, input_shape=(n_words,), activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile network\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'mse', 'binary_accuracy'])\n",
        "print(n_words)\n",
        "print(len(xTrain), len(yTrain))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4580\n",
            "1567 1567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf3LWIROp7w3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit network\n",
        "model.fit(xTrain, yTrain, validation_data=(xTrain, yTrain), epochs=50, verbose=2, callbacks=[metrics])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rqy1n-lcCasc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict(xTest, batch_size=64, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(classification_report(yTest, y_pred_bool))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZCse7Wzp-BG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b04b7e34-da2c-413d-ef68-949ebe71123a"
      },
      "source": [
        "# evaluate\n",
        "loss, acc, mse, ba = model.evaluate(xTest, yTest, verbose=0)\n",
        "print('Test Accuracy: %f' % (acc*100))\n",
        "print('Loss: %f' % (loss*100))\n",
        "print('MSE: ', mse * 100)\n",
        "\n",
        "print(type(xTest))\n",
        "print(type(yTest))\n",
        "print(type(xTrain))\n",
        "print(type(yTrain))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 64.571428\n",
            "Loss: 140.693218\n",
            "MSE:  28.514987230300903\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'list'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDuowsBFVZeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#saving the model\n",
        "\n",
        "#model.save('path_to_model_run')\n",
        "save_model(model, \"path\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV8_tlew4KTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "\t# split into tokens by white space\n",
        "\ttokens = text.split()\n",
        "\t# remove punctuation from each token\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\ttokens = [w.translate(table) for w in tokens]\n",
        "\t# remove remaining tokens that are not alphabetic\n",
        "\ttokens = [word for word in tokens if word.isalpha()]\n",
        "\t# filter out stop words\n",
        "\tstop_words = set(stopwords.words('english'))\n",
        "\ttokens = [w for w in tokens if not w in stop_words]\n",
        "\t# filter out short tokens\n",
        "\ttokens = [word for word in tokens if len(word) > 1]\n",
        "\t#convert to lowercase\n",
        "\tfor i in range(len(tokens)):\n",
        "\t\ttokens[i] = tokens[i].lower()\n",
        "\t\n",
        "\treturn tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs6jIBsk2DIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classify a text as negative (0) or positivte (1)\n",
        "def predict_sentiment(review, vocab, tokenizer, model):\n",
        "\t# clean\n",
        "\ttokens = clean_text(review)\n",
        "\t# filter by vocab\n",
        "\ttokens = [w for w in tokens if w in vocab]\n",
        "\t# convert to line\n",
        "\tline = ' '.join(tokens)\n",
        "\t# encode\n",
        "\tencoded = tokenizer.texts_to_matrix([line], mode='freq')\n",
        "\t# prediction\n",
        "\tyhat = model.predict(encoded, verbose=0)\n",
        "\treturn round(yhat[0,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H29wG_I7zSQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_scoreclass Metrics(Callback):def on_train_begin(self, logs={}):\n",
        " self.val_f1s = []\n",
        " self.val_recalls = []\n",
        " self.val_precisions = []\n",
        " \n",
        "def on_epoch_end(self, epoch, logs={}):\n",
        " val_predict = (np.asarray(self.model.predict(self.model.validation_data[0]))).round()\n",
        " val_targ = self.model.validation_data[1]\n",
        " _val_f1 = f1_score(val_targ, val_predict)\n",
        " _val_recall = recall_score(val_targ, val_predict)\n",
        " _val_precision = precision_score(val_targ, val_predict)\n",
        " self.val_f1s.append(_val_f1)\n",
        " self.val_recalls.append(_val_recall)\n",
        " self.val_precisions.append(_val_precision)\n",
        " print “ — val_f1: %f — val_precision: %f — val_recall %f” %(_val_f1, _val_precision, _val_recall)\n",
        " return\n",
        " \n",
        "metrics = Metrics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqHitU3aw6iV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#new_model = tf.keras.models.load_model('path_to_model_run')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOihDvY-2jaY",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "190ac52d-ae9c-45e9-8daf-136f9ad1dd2a"
      },
      "source": [
        "# test positive text\n",
        "# text1 = \"'Xiao Xingchen? Are you alright?' Xue Yang said anxiously as he saw the daozhang walking towards him. 'Yes, I am.' 'Oh, that's good to hear. Don't get hurt. A-Qing will never let me hear the end of it. Stay safe, alright?' 'Of course. I'm sorry that you have to worry about me. 'Oh, it's fine. I just want you to be safe, you know?'\"\n",
        "# print(predict_sentiment(text1, vocab, tokenizer, model))\n",
        "# # # test negative text\n",
        "# text2 = \"'Xue Yang!' Song Lan's angry voice echoed across the empty village. Xue Yang grinned and shrugged casually. 'What, I didn't hurt him! Why are you so angry?' 'You tricked him! You fooled him! I can't stand you, you criminal!'\"\n",
        "# print(predict_sentiment(text2, vocab, tokenizer, model))\n",
        "\n",
        "# text3 = \"'Hinata!' We're going to be late!' Komaeda called. 'Coming!' Hinata yelled, and he grabbed a slice of toast as he ran out the door. 'Thanks for reminding me,' he said breathlessly before taking a bite of toast. 'No problem,' Komaeda said, laughing. 'It's what friends do, no?' He began skipping down the sidewalk, singing out, 'Last day of school! Last do of school! Aren't you excited, Hinata?' 'Kind of,' his friend replied. 'I just don't know what I'll do this summer. 'We can go to the fairs together! The pool!' 'I never win anything at fairs...' 'Well, with my luck, I'll help you win!' 'Uh, Komaeda, isn't that cheating?' 'But we win, don't we?' 'Yeah, I guess we do...'\"\n",
        "# print(predict_sentiment(text3, vocab, tokenizer, model))\n",
        "\n",
        "text_and_dropdown = \"\\\"You tricked me.\\\" Baizan whispered, the realization of everything that occurred finally sinking in, and she collapsed in despair.. \\\"You lied!\\\" \\\"And what about it?\\\" Chaojun said casually. \\\"Sure, I'm evil. Sure, I tricked. Sure, I lied. But we're still friends, right?\\\" \\\"Never!\\\" she looked away, tears falling from her eyes. \\\"I can't believe that this is happening.\\\" \\\"Well, you'd better believe it, he snapped back, voice venomous. \\\"Nobody can stop me. Don't think that you'll succeed whether others failed. You aren't any more special than them. You have a duty to adhere to. Shut up and do your work. I don't want to hear you again.\\\" \\\"You!\\\" \\\"Shut up!\\\"\" #@param [\"'Xiao Xingchen? Are you alright?' Xue Yang said anxiously as he saw the daozhang walking towards him. 'Yes, I am.' 'Oh, that's good to hear. Don't get hurt. A-Qing will never let me hear the end of it. Stay safe, alright?' 'Of course. I'm sorry that you have to worry about me. 'Oh, it's fine. I just want you to be safe, you know?'\", \"'Xue Yang!' Song Lan's angry voice echoed across the empty village. Xue Yang grinned and shrugged casually. 'What, I didn't hurt him! Why are you so angry?' 'You tricked him! You fooled him! I can't stand you, you criminal!'\", \"'Hinata!' We're going to be late!' Komaeda called. 'Coming!' Hinata yelled, and he grabbed a slice of toast as he ran out the door. 'Thanks for reminding me,' he said breathlessly before taking a bite of toast. 'No problem,' Komaeda said, laughing. 'It's what friends do, no?' He began skipping down the sidewalk, singing out, 'Last day of school! Last do of school! Aren't you excited, Hinata?' 'Kind of,' his friend replied. 'I just don't know what I'll do this summer. 'We can go to the fairs together! The pool!' 'I never win anything at fairs...' 'Well, with my luck, I'll help you win!' 'Uh, Komaeda, isn't that cheating?' 'But we win, don't we?' 'Yeah, I guess we do...'\"] {allow-input: true}\n",
        "prediction = predict_sentiment(text_and_dropdown, vocab, tokenizer, model)\n",
        "\n",
        "if (prediction == 0):\n",
        "    print(\"Negative.\")\n",
        "    print(prediction)\n",
        "else:\n",
        "    print(\"Positive.\")\n",
        "    print(prediction)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Negative.\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSVlkQtOpJyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving xTrainLines\n",
        "rows = zip(xTrainLines)\n",
        "\n",
        "with open('xTrainLines.csv','w') as result_file:\n",
        "    wr = csv.writer(result_file)\n",
        "    for row in rows:\n",
        "        wr.writerow(row)\n",
        "\n",
        "# saving xTestLines\n",
        "rows = zip(xTestLines)\n",
        "\n",
        "with open('xTestLines.csv','w') as result_file:\n",
        "    wr = csv.writer(result_file)\n",
        "    for row in rows:\n",
        "        wr.writerow(row)\n",
        "\n",
        "# saving yTrain\n",
        "rows = zip(yTrain)\n",
        "\n",
        "with open('yTrain.csv','w') as result_file:\n",
        "    wr = csv.writer(result_file)\n",
        "    for row in rows:\n",
        "        wr.writerow(row)\n",
        "\n",
        "# saving yTest\n",
        "rows = zip(yTest)\n",
        "\n",
        "with open('yTest.csv','w') as result_file:\n",
        "    wr = csv.writer(result_file)\n",
        "    for row in rows:\n",
        "        wr.writerow(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzhhfKCq8hBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('vocabCount.csv', encoding='utf-8-sig', mode='w') as result_file:\n",
        "  writer=csv.writer(result_file)\n",
        "  for key, value in vocab.items():\n",
        "    for (row in rows):\n",
        "      writer.writerow(tag + \": \" + str(count) + '\\n')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_RC6MiPwGRH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "57d8129a-6832-4b17-fd1f-baf596571e24"
      },
      "source": [
        "new_model = tf.keras.models.load_model('path_to_model_run5')\n",
        "xTest2 = xTest.tolist()\n",
        "\n",
        "print(type(yTest))\n",
        "\n",
        "loss2, acc2, mse2, ba2 = new_model.evaluate(xTest2, yTest, verbose=0)\n",
        "print('Loss: %f' % (mse2*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "Loss: 32.621920\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}